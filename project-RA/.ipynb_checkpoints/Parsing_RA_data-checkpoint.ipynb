{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-15T19:58:36.511926Z",
     "start_time": "2020-09-15T19:58:36.506942Z"
    }
   },
   "source": [
    "# Import relevant packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-15T18:13:12.337357Z",
     "start_time": "2020-09-15T18:13:12.331377Z"
    }
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-15T19:59:19.030310Z",
     "start_time": "2020-09-15T19:59:19.025321Z"
    }
   },
   "source": [
    "# Consolidate all excel files into a pandas df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# folder containing excel files\n",
    "datapath = \"./backup/\"\n",
    "\n",
    "# set all .xlsx files in folder to a list\n",
    "allfiles = glob.glob(datapath + \"*.xlsx\")\n",
    "df = pd.DataFrame()\n",
    "\n",
    "# for loop to aquire all excel files in folder\n",
    "for f in allfiles:\n",
    "    data = pd.read_excel(f, 'Sheet1')\n",
    "    df = df.append(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start parsing.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-15T19:50:14.381442Z",
     "start_time": "2020-09-15T19:50:14.373402Z"
    }
   },
   "outputs": [],
   "source": [
    "df_clean = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-15T19:50:14.678679Z",
     "start_time": "2020-09-15T19:50:14.665712Z"
    }
   },
   "outputs": [],
   "source": [
    "df_clean.reset_index(drop=True, inplace=True)\n",
    "df_clean.drop(columns=['Unnamed: 0', 'id'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-15T19:50:26.589566Z",
     "start_time": "2020-09-15T19:50:25.065193Z"
    }
   },
   "outputs": [],
   "source": [
    "df_clean['complaint'] = df_clean['complaint'].fillna('')\n",
    "\n",
    "#cleaning [''] inside relevant values\n",
    "for col in df_clean.columns:\n",
    "    try:\n",
    "        df_clean[col] = df_clean[col].apply(lambda x: x.strip(\"['']\") if x==x else x) \n",
    "    except:\n",
    "        pass\n",
    "\n",
    "#feature engineering \n",
    "df_clean['ID'] = df_clean['details'].apply(lambda x: re.findall('ID: (\\d{9})', x))\n",
    "df_clean['date'] = df_clean['details'].apply(lambda x: re.findall('\\d\\d/\\d\\d/\\d\\d', x))\n",
    "df_clean['hour'] = df_clean['details'].apply(lambda x: re.findall('Ã s (\\d\\dh\\d\\d)', x))\n",
    "df_clean['city'] = df_clean['details'].apply(lambda x: re.findall('^(.*) - \\w\\w ID', x))\n",
    "df_clean['state'] = df_clean['details'].apply(lambda x: re.findall('(\\w\\w) ID', x))\n",
    "df_clean['len_complaint'] = df_clean['complaint'].apply(lambda x: len(str(x)))\n",
    "df_clean['len_words'] = df_clean['complaint'].apply(lambda x: len(str(x).split()))\n",
    "\n",
    "#'unlisting' certain columns\n",
    "df_clean = df_clean.applymap(lambda x: x if not isinstance(x, list) else x[0] if len(x) else '')\n",
    "df_clean['hour'] = df_clean['hour'].apply(lambda x: re.sub('h', ':', x))\n",
    "\n",
    "#dropping non-relevant columns after parsing\n",
    "df_clean.drop(columns='details', inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving and closing file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-15T20:02:45.404345Z",
     "start_time": "2020-09-15T20:02:44.677743Z"
    }
   },
   "outputs": [],
   "source": [
    "df_clean.reset_index(drop=False, inplace=True)\n",
    "df_clean.to_csv('./final/final_dataset.csv', sep=';', encoding = 'iso-8859-1')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
